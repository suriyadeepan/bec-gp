import numpy as np
import trottersuzuki as ts
import math
import pickle
import os
import time

from matplotlib import pyplot as plt
from neuralbec import utils

from multiprocessing.pool import ThreadPool as Pool

logger = utils.get_logger(__name__)


def harmonic_potential(x, y):
  """ Harmonic Potential

      ( x^2 + y^2 ) / 2
  """
  return 0.5 * (x**2 + y**2)


def custom_potential_1(x, y):
  """ Custom Potential

      0.5x^2 + 24cos^2(x)
  """
  return 0.5 * (x**2) + 24 * (math.cos(x) ** 2)


def generate_varg(fn, num_samples, filename, g_low=0, g_high=500, save_every=100):
  """Create dataset based on data generated by `fn` by varying `g`

  Parameters
  ----------
  fn : function
    Data (Particle Density) generating function

  Returns
  -------
  dict
    A dictionary of datapoints and reference points

  """
  datapoints = []
  step = 0
  for g in np.random.uniform(g_low, g_high, num_samples):
    # generate particle density
    out = fn(g)
    datapoints.append((out['g'], out['psi']))
    step += 1
    logger.info('[{}] {}'.format(step, g))
    # every few iterations, save datapoints to disk
    if step and step % save_every == 0:
      # create datadict
      datadict = { ref : out[ref] for ref in ['x', 'y', 'z']
          if ref in out }
      # attach datapoints
      datadict['data'] = datapoints
      # save to file
      save(datadict, '{}.{}.{}'.format(filename, save_every, step))
      # clear datapoints
      datapoints = []


def generate_parallel(gen_fn, inputs, filename, save_every=20):
  # create a pool
  pool = Pool(4)  # os.cpu_count())
  # num of iterations
  iterations = len(inputs) // save_every
  # execute in iterations
  for i in range(iterations):
    # start timer
    start_time = time.time()
    # execute pool
    outputs = pool.map(gen_fn, inputs[ i * save_every : (i + 1) * save_every ])
    # structure of outputs
    # [ 'x' : ..., 'y' : ..., 'g' : ..., 'psi' : ... ]
    # get reference points
    o = outputs[0]
    datadict = { ref : o[ref] for ref in ['x', 'y', 'z']
        if ref in o }
    # get data
    datadict['data'] = [ (o['g'], o['psi']) for o in outputs ]
    # write to disk
    save(datadict, '{}.{}.{}'.format(filename, save_every, i))
    logger.info('_________ {} seconds _________'.format(
      time.time() - start_time))


def particle_density_BEC1D(dim, radius, angular_momentum, time_step,
    coupling, potential_fn, iterations, wave_function):
  """Estimate Particle Density of 1-dimensional BEC system

  Parameters
  ----------
  dim : int
    dimensions of lattice
  radius : float
    physical radius
  angular_momentum : float
    quantum number
  time_step : float
    time steps
  coupling : float
    coupling strength (g)
  iterations : int
    number of iterations of trotter-suzuki

  Returns
  -------
  dict, numpy.ndarray
    reference points, particle density of evolved system
  """
  # Set up lattice
  grid = ts.Lattice1D(dim, radius)
  # initialize state
  state = ts.State(grid, angular_momentum)
  state.init_state(wave_function)
  # init potential
  potential = ts.Potential(grid)
  potential.init_potential(potential_fn)  # harmonic potential
  # build hamiltonian with coupling strength `g`
  hamiltonian = ts.Hamiltonian(grid, potential, 1., coupling)
  # setup solver
  solver = ts.Solver(grid, state, hamiltonian, time_step)
  # Evolve the system
  solver.evolve(iterations, False)
  # Compare the calculated wave functions w.r.t. groundstate function
  # psi = np.sqrt(state.get_particle_density()[0])
  psi = state.get_particle_density()[0]
  # psi / psi_max
  psi = psi / max(psi)

  print('mean', np.mean(psi))
  print('sigma', np.var(psi))

  return {
      'x' : grid.get_x_axis(),
      'g' : coupling,
      'psi' : psi
      }


def particle_density_BEC2D(dim, radius, angular_momentum, time_step,
  coupling, potential_fn, iterations):
  """Estimate Particle Density of 2-dimensional BEC system

  Parameters
  ----------
  dim : int
    dimensions of lattice
  radius : float
    physical radius
  angular_momentum : float
    quantum number
  time_step : float
    time steps
  coupling : float
    coupling strength (g)
  iterations : int
    number of iterations of trotter-suzuki

  Returns
  -------
  dict, numpy.ndarray
    reference points, particle density of evolved system
  """
  # Set up lattice
  grid = ts.Lattice2D(dim, radius)
  # initialize state
  state = ts.GaussianState(grid, angular_momentum)
  # create an harmonic potential
  potential = ts.HarmonicPotential(grid, 1., 1. / np.sqrt(2.))
  # build hamiltonian with coupling strength `g`
  hamiltonian = ts.Hamiltonian(grid, potential, 1., coupling)
  # setup solver
  solver = ts.Solver(grid, state, hamiltonian, time_step)
  # Evolve the system
  solver.evolve(iterations, True)
  # psi / psi_max
  psi = state.get_particle_density()
  # psi / psi_max
  psi = psi / psi.max()

  return {
      'x' : grid.get_x_axis(),
      'y' : grid.get_y_axis(),
      'g' : coupling,
      'psi' : psi
      }


# TODO : move to plot.py
def plot_wave_function(x, psi, fontsize=16, title=None,
  save_to=None, show=True, color='green'):
  """Plot Wave Function vs. x"""
  # set title
  if title:
    plt.title(title)
  # settings
  plt.plot(x, psi, 'o', markersize=3, color=color)
  plt.xlabel('x', fontsize=fontsize)
  plt.ylabel(r'$\psi$', fontsize=fontsize)
  # save figure
  if save_to:
    plt.savefig(save_to)
    logger.info('Figure saved to {}'.format(save_to))
  # disply image
  if show:
    plt.show()


# TODO : move to plot.py
def plot_wave_function_2d(x, y, psi, fontsize=16,
  title=None, save_to=None, show=True):
  """Plot Wave Function vs. (x, y)"""
  # set title
  if title:
    plt.title(title)
  # settings
  plt.xlabel('x', fontsize=fontsize)
  plt.ylabel(r'$\psi$', fontsize=fontsize)
  # plot psi vs. (x, y)
  plt.pcolormesh(x, y, psi)
  # save figure
  if save_to:
    plt.savefig(save_to)
    logger.info('Figure saved to {}'.format(save_to))
  # disply image
  if show:
    plt.show()


def load(name, path='data/'):
  filename = os.path.join(path, name)
  datadump = pickle.load(open(filename, 'rb'))
  inputs = [ g for g, density in datadump['data'] ]
  outputs = [ density for g, density in datadump['data'] ]
  reference = { axis : datadump[axis]
      for axis in ['x', 'y', 'z', 'r'] if axis in datadump
      }
  return inputs, outputs, reference


def save(datadict, name, path='data/'):
  """Save Data Dictionary to disk

  Parameters
  ----------
  datadict : dict
    data dictionary { 'x' : [ ... ], 'data' : [ (.., ..), .. ] }
  name : str
    file name to save data
  path : str
    path to file
  """
  filename = os.path.join(path, name)
  pickle.dump(datadict, open(filename, 'wb'))
  logger.info('Saved to {}'.format(filename))


def make_dataset(name):
  inputs, psi, reference = load('{}.data'.format(name))
  # train/test split
  trainset, testset = utils.split_dataset(  # train/test split
      utils.shuffle((inputs, psi)),         # shuffle dataset
      ratio=0.7
      )
  # test/valid split
  testset, validset = utils.split_dataset(testset, ratio=0.5)

  return (trainset, testset, validset)
